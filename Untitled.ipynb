{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d77dd1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d08ba283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_params(thread_size: int, block_size: int, grid_size: int, csv_out_path: str, window: int):\n",
    "    return \"\"\"\n",
    "#ifndef PARAMS_CUH\n",
    "#define PARAMS_CUH\n",
    "\n",
    "#define ITEMS_PER_THREAD {0}\n",
    "#define THREADS_PER_BLOCK {1}\n",
    "#define AMOUNT_BLOCKS {2}\n",
    "#define CSV_OUTPUT_PATH \"{3}\"\n",
    "#define WINDOW \"{4}\"\n",
    "#endif\n",
    "    \"\"\".format(thread_size, block_size, grid_size, csv_out_path, window)\n",
    "\n",
    "def write_params(params: str):\n",
    "    with open(\"baseline/params.cuh\", \"w\") as f:\n",
    "        f.write(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ff3f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_params(gen_params(2, 512, 32, \"Benchmarking/block_size/1.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "40f6855f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_code(max_block_size, path, window, step = 1):\n",
    "    os.popen(f\"mkdir -p {path}\").read()\n",
    "    for i in range(1, max_block_size, step):\n",
    "        os.popen(f\"mkdir -p Benchmarking/test_builds/{i}\").read()\n",
    "        write_params(gen_params(2, 512, i, f\"{path}/{i}.csv\"))\n",
    "        os.popen(f\"cp -rf baseline Benchmarking/test_builds/{i}\").read()\n",
    "        os.popen(f\"cp -rf shared Benchmarking/test_builds/{i}\").read()\n",
    "        os.popen(f\"cp -rf Makefile Benchmarking/test_builds/{i}\").read()\n",
    "\n",
    "\n",
    "def compile_code(max_block_size, step = 1):\n",
    "    running = []\n",
    "    i = 1\n",
    "    for i in range(1, max_block_size, step):\n",
    "        running.append(os.popen(f\"cd Benchmarking/test_builds/{i}; nvcc baseline/main.cu\"))\n",
    "        if len(running) > 36:\n",
    "            for r in running:\n",
    "                r.read()\n",
    "            running = []\n",
    "            print(i)\n",
    "        i += 1\n",
    "    for r in running:\n",
    "        r.read()\n",
    "\n",
    "def run(max_block_size, step = 1):\n",
    "    !mkdir -p Benchmarking/block_size_descend_with_sync_without_shared\n",
    "    for i in range(1, max_block_size, step):\n",
    "        test = os.popen(f\"./Benchmarking/test_builds/{i}/a.out\").read()\n",
    "        if \"success\" not in test:\n",
    "            print(\"BAD EXEC; abort\")\n",
    "            print(test)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Working {0}\".format(i))\n",
    "            \n",
    "def exec_run(max_block_size, path, window, step = 1):\n",
    "    gen_code(max_block_size, path, step, window)\n",
    "    compile_code(max_block_size, step)\n",
    "    run(max_block_size, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_run(10000, \"Benchmarking/window_1\", 1, 50)\n",
    "exec_run(10000, \"Benchmarking/window_5\", 5, 50)\n",
    "exec_run(10000, \"Benchmarking/window_25\", 25, 50)\n",
    "exec_run(10000, \"Benchmarking/window_50\", 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b33f6619",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Benchmarking/retry_5/2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [114]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     14\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(avgs, label \u001b[38;5;241m=\u001b[39m name)\n\u001b[0;32m---> 16\u001b[0m plot_results(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBenchmarking/retry_5/\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10001\u001b[39m, \u001b[38;5;241m100\u001b[39m)    \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mplot_results(\"../descend/Benchmarking/correct_iters_window_1/{0}.csv\", \"Descend Window 1\")\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03mplot_results(\"../descend/Benchmarking/correct_iters_window_5/{0}.csv\", \"Descend Window 5\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03mplot_results(\"Benchmarking/fix_block_50/{0}.csv\", \"Hand written 50\")\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "Input \u001b[0;32mIn [114]\u001b[0m, in \u001b[0;36mplot_results\u001b[0;34m(path, name, max_v, step)\u001b[0m\n\u001b[1;32m      3\u001b[0m avgs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# First 5 values tend to be longer than the other\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m a: \u001b[38;5;28mfloat\u001b[39m(a\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m      9\u001b[0m             csvfile\u001b[38;5;241m.\u001b[39mreadlines()[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     10\u001b[0m         ))[\u001b[38;5;241m0\u001b[39m:]\n\u001b[1;32m     11\u001b[0m         avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(results) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(results)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Benchmarking/retry_5/2.csv'"
     ]
    }
   ],
   "source": [
    "def plot_results(path, name, max_v, step):\n",
    "    i = 1\n",
    "    avgs = []\n",
    "    while i <= 300:\n",
    "        with open(path.format(i), \"r\") as csvfile:\n",
    "            # First 5 values tend to be longer than the other\n",
    "            results = list(map(\n",
    "                lambda a: float(a.split(',')[0]),\n",
    "                csvfile.readlines()[1:]\n",
    "            ))[0:]\n",
    "            avg = sum(results) / len(results)\n",
    "            avgs.append(avg)\n",
    "        i += 1\n",
    "    plt.plot(avgs, label = name)\n",
    "\n",
    "plot_results(\"Benchmarking/big_block/{0}.csv\", \"test\", 10001, 100)    \n",
    "\"\"\"\n",
    "plot_results(\"../descend/Benchmarking/correct_iters_window_1/{0}.csv\", \"Descend Window 1\")\n",
    "plot_results(\"../descend/Benchmarking/correct_iters_window_5/{0}.csv\", \"Descend Window 5\")\n",
    "plot_results(\"../descend/Benchmarking/correct_iters_window_25/{0}.csv\", \"Descend Window 25\")\n",
    "plot_results(\"Benchmarking/retry_2/{0}.csv\", \"Hand written 1 foo\")\n",
    "#plot_results(\"Benchmarking/retry_5/{0}.csv\", \"Hand written 5 foo\")\n",
    "plot_results(\"Benchmarking/fix_block_1/{0}.csv\", \"Hand written 1\")\n",
    "plot_results(\"Benchmarking/fix_block_5/{0}.csv\", \"Hand written 5\")\n",
    "plot_results(\"Benchmarking/fix_block_25/{0}.csv\", \"Hand written 25\")\n",
    "plot_results(\"Benchmarking/fix_block_50/{0}.csv\", \"Hand written 50\")\n",
    "\"\"\"\n",
    "plt.legend()\n",
    "plt.ylabel('Run Time of Kernel')\n",
    "plt.xlabel('Amount of Blocks with 512 Threads')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd4d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "print(f\"Window 1: {statistics.fmean(avgs)}\")\n",
    "print(f\"Window 5: {statistics.fmean(avgs_2)}\")\n",
    "print(f\"Window 25: {statistics.fmean(avgs_3)}\")\n",
    "print(f\"Window 50: {statistics.fmean(avgs_4)}\")\n",
    "print(f\"Window opt: {statistics.fmean(avgs_5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6f79b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
